{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLow-Frequency Flat (LFlat) Program using a Markov Chain Monte Carlo (MCMC) optimizer\\n\\n:Author: Diana Kossakowski\\n\\n:Organization: Space Telescope Science Institute\\n\\n:History:\\n    * Aug 2016 Finished\\n\\nExamples\\n--------\\nTo call from command line::\\n    python FF.py --datafile '/user/dkossakowski/sbc_f125lp.phot' --chosenfunc 'poly' --n 3\\n    --nwalkers 100 --nsteps 700 --filmcmc '/user/dkossakowski/poly3_100_700_mcmc.txt'\\n    --filcoeff '/user/dkossakowski/poly3_100_700_coeff.txt' --figpath '/user/dkossakowski/poly3_100_700_'\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Low-Frequency Flat (LFlat) Program using a Markov Chain Monte Carlo (MCMC) optimizer\n",
    "\n",
    ":Author: Diana Kossakowski\n",
    "\n",
    ":Organization: Space Telescope Science Institute\n",
    "\n",
    ":History:\n",
    "    * Aug 2016 Finished\n",
    "\n",
    "Examples\n",
    "--------\n",
    "To call from command line::\n",
    "    python FF.py --datafile '/user/dkossakowski/sbc_f125lp.phot' --chosenfunc 'poly' --n 3\n",
    "    --nwalkers 100 --nsteps 700 --filmcmc '/user/dkossakowski/poly3_100_700_mcmc.txt'\n",
    "    --filcoeff '/user/dkossakowski/poly3_100_700_coeff.txt' --figpath '/user/dkossakowski/poly3_100_700_'\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "Every import should be pretty straight forward.\n",
    "Notes:\n",
    "* matplotlib.use('Agg') makes it so the figure doesn't have to pop up when you save it\n",
    "* emcee is the Python package for MCMC\n",
    "* DataInfoTab is the code I made for filtering the data SHOULD I JUST PUT IT IN THIS FILE??\n",
    "* corner is the Python package that makes the triangle plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global Imports\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import warnings\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "#from multiprocessing import Pool\n",
    "\n",
    "# Local Imports\n",
    "import emcee\n",
    "\n",
    "# Functions\n",
    "from sympy import *\n",
    "import numpy.polynomial.chebyshev as cheb\n",
    "import numpy.polynomial.legendre as leg\n",
    "from scipy import integrate\n",
    "\n",
    "# Data\n",
    "from astropy.table import Table, Column\n",
    "       \n",
    "# Plotting\n",
    "import corner                              # local import\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Note for all functions: \n",
    "* used Sympy to create x and y as Symbols and then convert them into a function using lambdify\n",
    "* lambdify needs to take in a list and not array\n",
    "* the constant term needs to be 1 + 0*x but lambdify makes it just 1. This means that if you call the function on an x array and y array, the 0th element will be just the int 1 and not an array of ones (see example below on how to deal with it)\n",
    "\n",
    "Three parts:\n",
    "(1) defining the functions\n",
    "(2) getting the function\n",
    "(3) defining and using integration"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Return for all functions:\n",
    "    funclist -- A list of the different components of the function \n",
    "                (elements are Symbol types) -- useful for printing\n",
    "    f        -- A function made from funclist and takes in two\n",
    "                parameters, x and y -- x and y can either be single \n",
    "                values (ints or doubles) or they need to be arrays \n",
    "                (not lists)\n",
    "                            \n",
    "# Example\n",
    ">>> func2read, func2fit = get_function(chosenfunc = 'cheb', n = 1)\n",
    ">>> print func2read\n",
    "[1, x, y, x*y]\n",
    ">>> print func2fit\n",
    "<function <lambda> at 0x120fa8f50>\n",
    ">>> print func2fit(1, 1)\n",
    "[1, 1, 1, 1]\n",
    ">>> print func2fit(1, 2)\n",
    "[1, 2, 1, 2]\n",
    "### if z = 1+x+y+x*y then z = np.sum(func2fit(x,y))\n",
    ">>> print np.sum(func2fit(1,2))     \n",
    "6\n",
    "\n",
    "### If you want to put in multiple x and y values you need to make them arrays and not lists\n",
    ">>> x, y = np.array([1, 2]), np.array([3, 4])\n",
    ">>> test = func2fit(x, y)\n",
    ">>> print test\n",
    "[1, array([3, 4]), array([1, 2]), array([3, 8])]\n",
    "### You can see how the 0th element is just the int 1, and not an array like the other elements\n",
    ">>> test[0] = np.ones(len(x)) # np.ones(len(y))\n",
    ">>> print test\n",
    "[array([ 1.,  1.]), array([3, 4]), array([1, 2]), array([3, 8])]\n",
    ">>> print np.sum(test, axis=0)\n",
    "[  8.  15.]\n",
    "\n",
    "### Integration\n",
    ">>> mcmccoeff, chosenfunc, n = [1, 2, 3, 4], 'cheb', 1\n",
    ">>> intnum = integrate.nquad(funcintegrate, [bounds_x(), bounds_y()], args = (mcmccoeff, chosenfunc, n,))[0]  \n",
    ">>> print intnum\n",
    "\n",
    ">>> intnum /= area()\n",
    ">>> print intnum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norder2dpoly(n):\n",
    "    ''' \n",
    "    Purpose\n",
    "    -------\n",
    "    Create the 2D nth order polynomial        \n",
    "    How it works:\n",
    "        A 2nd order can be grouped like: 1; x1y0 x0y1; x2y0 x1y1 x0y2\n",
    "        (where x0 = x**0, x1 = x**1 and so on)\n",
    "        So the degree of x starts at a certain number (currnum) and decreases\n",
    "        by one, while the degree of y starts at 0 and increase by one until currnum\n",
    "    Note: \n",
    "        * Just found out (2 weeks later after making this), that there \n",
    "        exists numpy.polynomial.polynomial.polyvander2d which does what I made\n",
    "    '''\n",
    "    x = Symbol('x')\n",
    "    y = Symbol('y')\n",
    "    funcarr = np.array([])\n",
    "    for currnum in range(n+1):\n",
    "        xi = currnum\n",
    "        yi = 0\n",
    "        while yi <= currnum:\n",
    "            funcarr = np.append(funcarr, x**xi * y**yi)\n",
    "            yi += 1\n",
    "            xi -= 1\n",
    "    funclist = funcarr.tolist()     # lambdify only takes in lists and not arrays\n",
    "    f = lambdify((x, y), funclist)  # lambdify looks at 1 + 0*x as 1 and makes f[0] = 1\n",
    "    return funclist, f              # return the list in case we want to look at how the function is\n",
    "        \n",
    "def norder2dcheb(nx, ny):\n",
    "    ''' \n",
    "        Purpose\n",
    "        -------\n",
    "        Create the 2D nx th and ny th order Chebyshev polynomial using\n",
    "        numpy.polynomial.chebyshev.chebvander2d(x, y, [nx, ny])\n",
    "    '''\n",
    "    x = Symbol('x')\n",
    "    y = Symbol('y')\n",
    "    funcarr = cheb.chebvander2d(x,y,[nx,ny])\n",
    "    funcarr = funcarr[0]            # Because chebvander2d returns a 2d matrix\n",
    "    funclist = funcarr.tolist()     # lambdify only takes in lists and not arrays\n",
    "    f = lambdify((x, y), funclist)  # Note: lambdify looks at 1 as 1 and makes f[0] = 1 and not an array\n",
    "    return funclist, f\n",
    "    \n",
    "def norder2dlegendre(nx, ny):\n",
    "    ''' \n",
    "        Purpose\n",
    "        -------\n",
    "        Create the 2D nx th and ny th order Legendre polynomial using\n",
    "        numpy.polynomial.legendre.legvander2d(x, y, [nx, ny])\n",
    "    '''\n",
    "    x = Symbol('x')\n",
    "    y = Symbol('y')\n",
    "    funcarr = leg.legvander2d(x,y,[nx,ny])\n",
    "    funcarr = funcarr[0]            # Because chebvander2d returns a 2d matrix\n",
    "    funclist = funcarr.tolist()     # lambdify only takes in lists and not arrays\n",
    "    f = lambdify((x, y), funclist)  # Note: lambdify looks at 1 as 1 and makes f[0] = 1 and not an array\n",
    "    return funclist, f\n",
    "    \n",
    "def get_function(chosenfunc, n):\n",
    "    nx = ny = n\n",
    "    if chosenfunc == 'poly':\n",
    "        func2read, func2fit = norder2dpoly(n) \n",
    "    elif chosenfunc == 'cheb':\n",
    "        func2read, func2fit = norder2dcheb(nx, ny)        # nx th and ny th order 2d Chebyshev Polynomial\n",
    "    elif chosenfunc == 'leg':\n",
    "        func2read, func2fit = norder2dlegendre(nx, ny) \n",
    "    return [func2read, func2fit]\n",
    "    \n",
    "########## Integration\n",
    "def funcintegrate(x, y, coeff, chosenfunc, n):\n",
    "    func2read, func2fit = get_function(chosenfunc, n)\n",
    "    return np.sum(func2fit(x, y) * coeff)\n",
    "\n",
    "def bounds_x():\n",
    "    if SCALE2ONE:\n",
    "        return [-1, 1]\n",
    "    else:\n",
    "        return [0, CHIPXLEN]\n",
    "def bounds_y():\n",
    "    if SCALE2ONE:\n",
    "        return [-1, 1]\n",
    "    else:\n",
    "        return [0, CHIPYLEN]\n",
    "def area():\n",
    "    return np.sum(np.abs(bounds_y() + bounds_x()))\n",
    "##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table\n",
    "## Making the Table\n",
    "This part makes the Astropy Table. We are assuming that the user gives us the basic information of:\n",
    "\n",
    "###### starID, x position, y position, flux measurement, flux error\n",
    "\n",
    "The data file can have more information: and then need to specify which columns correspond to what name and type. It is also an option to remove unnecessary columns such as 'filenum' and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_avgflux(tab):\n",
    "    ''' Create new columns for average flux and average flux error '''  \n",
    "    filler = np.arange(len(tab))\n",
    "    c1 = Column(data = filler, name = 'avgflux',       dtype = np.float64)\n",
    "    c2 = Column(data = filler, name = 'avgfluxerr',    dtype = np.float64)\n",
    "    tab.add_column(c1)\n",
    "    tab.add_column(c2)\n",
    "    \n",
    "    starIDarr = np.unique(tab['id'])\n",
    "    for star in starIDarr:\n",
    "        starindexes = np.where(tab['id'] == star)[0]    # the indexes in the tab of where the star is\n",
    "        currfluxes = tab[starindexes]['flux']           # the current fluxes (type = class <'astropy.table.column.Column'>)\n",
    "        currfluxerr = tab[starindexes]['fluxerr']       # the current flux errors (type = class <'astropy.table.column.Column'>)\n",
    "        avgerror = lambda errarr: np.sqrt(np.sum(errarr**2)) / len(errarr)\n",
    "        avgfluxerr = avgerror(currfluxerr)\n",
    "        for i, index in enumerate(starindexes):         # input the average flux and its error\n",
    "            tab[index]['avgflux'] = np.mean(currfluxes)\n",
    "            tab[index]['avgfluxerr'] = avgfluxerr\n",
    "    return tab\n",
    "\n",
    "def do_table(fil, names, types, removenames=[]):\n",
    "    ### Assuming that we are given flux and fluxerr -- need to make avgflux and avgfluxerr\n",
    "    print '******************************************'\n",
    "    print '*************** START TABLE **************'\n",
    "    print '******************************************'\n",
    "    data = np.genfromtxt(fil)\n",
    "    tab = Table(data, names=names, dtype=types)\n",
    "    tab.remove_columns(removenames)             # Remove columns that are not useful\n",
    "    #tab = make_avgflux(tab)                     # Create columns for 'avgflux' and 'avgfluxerr'\n",
    "    print 'The names of the columns in the Table:'\n",
    "    print tab.colnames\n",
    "    print '******************************************'\n",
    "    print '**************** END TABLE ***************'\n",
    "    print '******************************************'\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the Table\n",
    "This part filters the Astropy Table\n",
    "Filters applied:\n",
    "* Remove any particular stars\n",
    "* Remove any observations that are below a flux ratio (flux signal-to-noise)\n",
    "* Remove any stars that do not have the minimum number of observations\n",
    "* Look at the observations of each star and remove observations whose flux is not within a certain sigma for that star\n",
    "* Look at the data set and observations as a whole and remove any observations whose normalized delta flux are not within a certain sigma "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the Filters\n",
    "Below are the filter functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stars_tab(tab, min_num_obs = 4):\n",
    "    \"\"\"            *** Filter function ***\n",
    "    Purpose\n",
    "    -------\n",
    "    Removes the stars with less than a min num of observations from the table\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tab:                The Astropy table with all the information\n",
    "    min_num_obs:        The minimum number of observations required for a star \n",
    "                        to have (default = 4)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tab:                The filtered table after deleting all the stars with not\n",
    "                        enough observations\n",
    "    \"\"\"\n",
    "    starIDarr = np.uniqure(tab['id'])\n",
    "    removestarlist = [star for star in starIDarr if len(np.where(tab['id'] == star)[0]) < min_num_obs] # Get a list of the stars to remove\n",
    "    removetabindicies = np.array([])\n",
    "    for removestar in removestarlist:\n",
    "        removetabindicies = np.append(removetabindicies, np.where(tab['id'] == removestar)[0])\n",
    "    removetabindicies = map(int, removetabindicies) # need to make removing indicies ints \n",
    "    tab.remove_rows(removetabindicies)\n",
    "    return tab\n",
    "\n",
    "def remove_certain_star(tab, star_names):\n",
    "    '''           *** Filter function ***\n",
    "    Purpose\n",
    "    -------\n",
    "    Remove any stars in star_names from tab\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tab:                The Astropy table with all the information\n",
    "    star_names:         The list or array of the star names to remove\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    tab:                The filtered table after deleteing the stars in star_names\n",
    "    '''\n",
    "    removetabindicies = np.array([])\n",
    "    for removestar in star_names:\n",
    "        removetabindicies = np.append(removetabindicies, np.where(tab['id'] == removestar)[0])\n",
    "    removetabindicies = map(int, removetabindicies) # need to make removing indicies ints \n",
    "    tab.remove_rows(removetabindicies)\n",
    "    return tab\n",
    "\n",
    "def sigmaclip(z, low = 3, high = 3, num = 5):\n",
    "    \"\"\"           \n",
    "    Purpose\n",
    "    -------\n",
    "    Applies sigma clipping to an array\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z:                  The array that will be sigma clipped\n",
    "    low:                The lower bound of the sigma clip (Default = 3)\n",
    "    high:               The higher bound of the sigma clip (Default = 3)\n",
    "    num:                The maximum number of times the sigma clipping will iterate\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    remove_arr:         An array of the indexes that have been sigmaclipped\n",
    "    \n",
    "    * So if you want to get rid of those values in z; \n",
    "    do z = np.delete(z, remove_arr)\n",
    "    * Copied exactly from scipy.stats.sigmaclip with some variation to keep\n",
    "    account for the index(es) that is (are) being removed\n",
    "    \"\"\"\n",
    "    c = np.asarray(z).ravel()           # this will be changing\n",
    "    c1 = np.copy(c)                     # the very original array\n",
    "    delta = 1\n",
    "    removevalues = np.array([])\n",
    "    count = 0\n",
    "    while delta and count < num:\n",
    "        c_std = c.std()\n",
    "        c_mean = c.mean()\n",
    "        size = c.size\n",
    "        critlower = c_mean - c_std*low\n",
    "        critupper = c_mean + c_std*high\n",
    "        removetemp = np.where(c < critlower)[0]\n",
    "        removetemp = np.append(removetemp, np.where(c > critupper)[0])\n",
    "        removevalues = np.append(removevalues, c[removetemp])\n",
    "        c = np.delete(c, removetemp)\n",
    "        delta = size - c.size\n",
    "        count += 1\n",
    "    removevalues = np.unique(removevalues)\n",
    "    remove_arr = np.array([])\n",
    "    for val2remove in removevalues:\n",
    "        remove_arr = np.append(remove_arr, np.where(c1 == val2remove)[0])\n",
    "    remove_arr = map(int, remove_arr)\n",
    "    return remove_arr\n",
    "\n",
    "def sigmaclip_starmagflux(tab, flux = True, mag = False, low = 3, high = 3):\n",
    "    \"\"\"           *** Filter function ***\n",
    "    Purpose\n",
    "    -------\n",
    "    To remove any observations for each star that are not within a low sigma \n",
    "    and high simga (Ex. a star has mag values [24,24.5,25,25,25,50] --> the \n",
    "    observation with 50 will be removed from the table\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    tab:                The Astropy table with all the information\n",
    "    flux:               Boolean: True if we want to sigmaclip flux (Default is True)\n",
    "    mag:                Boolean: True if we want to sigmaclip mag  (Default is False)\n",
    "    low:                The bottom cutoff (low sigma); default is 3\n",
    "    high:               The top cutoff (high sigma); default is 3\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tab:                The updated Astropy table with obscure observations removed\n",
    "    \"\"\"\n",
    "    \n",
    "    removetabindices = np.array([])\n",
    "    for star in starIDarr:\n",
    "        starindexes = np.where(tab['id'] == star)[0]\n",
    "        if mag:\n",
    "            currmags = tab[starindexes]['mag']\n",
    "            remove_arr = sigmaclip(currmags, low, high)\n",
    "            removetabindicies = np.append(removetabindices, starindexes[remove_arr])\n",
    "        if flux:\n",
    "            currfluxes = tab[starindexes]['flux']\n",
    "            remove_arr = sigmaclip(currfluxes, low, high)\n",
    "            removetabindicies = np.append(removetabindices, starindexes[remove_arr])\n",
    "    removetabindicies = map(int, removetabindicies)\n",
    "    tab.remove_rows(removetabindicies)\n",
    "    return tab\n",
    "\n",
    "def sigmaclip_delmagdelflux(tab, flux = True, mag = False, low = 3, high = 3):\n",
    "    '''           *** Filter function ***\n",
    "    Purpose\n",
    "    -------\n",
    "    To remove any observations in the data set as a whole whose delta magnitude \n",
    "    and/or delta flux is not within a certain sigma\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    tab:                The Astropy table with all the information\n",
    "    flux:               Boolean: True if we want to sigmaclip flux (Default is True)\n",
    "    mag:                Boolean: True if we want to sigmaclip mag  (Default is False)\n",
    "    low:                The bottom cutoff (low sigma); default is 3\n",
    "    high:               The top cutoff (high sigma); default is 3\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tab:                The updated Astropy table with obscure observations removed\n",
    "    '''\n",
    "    if flux:\n",
    "        delfarr = (tab['flux'] - tab['avgflux']) / tab['avgflux']   # normalized flux\n",
    "        delfarr = np.asarray(delfarr)\n",
    "        # sigma clipping the delta fluxes\n",
    "        remove_arr = sigmaclip(delfarr, low, high)\n",
    "        tab.remove_rows(remove_arr)\n",
    "    if mag:\n",
    "        delmarr = (tab['mag'] - tab['avgmag']) / tab['avgmag']      # normalized mag\n",
    "        delmarr = np.asarray(delmarr)\n",
    "        # sigma clipping the delta magnitudes\n",
    "        remove_arr = sigmaclip(delmarr, low, high)\n",
    "        tab.remove_rows(remove_arr)\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below are the functions that make new Columns for the Astropy Table USING MAG -- NEED TO DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertmag2flux(mag, mag0 = 25, flux0 = 1):\n",
    "    ''' Converts a magnitude to a flux \n",
    "    -- assume zero-point mag is 0 and flux is a constant '''\n",
    "    return flux0 * 10**(.4*(mag0-mag))\n",
    "    \n",
    "def convertflux2mag(flux, mag0 = 25, flux0 = 1):\n",
    "    ''' Converts a flux into a magnitude\n",
    "    -- assume zero-point mag is 0 and flux is a constant ''' \n",
    "    return mag0 - 2.5 * np.log10(flux/flux0)\n",
    "    \n",
    "def make_avgmagandflux(tab):\n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "    To create six new columns to store the \n",
    "    (1) average magnitude               ['avgmag']\n",
    "    (2) average magnitude error         ['avgmagerr'] \n",
    "    (3) flux                            ['flux']\n",
    "    (4) flux error                      ['fluxerr']\n",
    "    (5) average flux                    ['avgflux']\n",
    "    (6) average flux error              ['avgfluxerr']\n",
    "    The magnitude readings are converted into fluxes and then the average flux \n",
    "    is taken and converted to magnitude to make the 'real' magnitude.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    tab:                The Astropy table with all the information\n",
    "    starIDarr:          The array of unique star IDs in the table\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tab:                The updated Astropy table\n",
    "    starIDarr:          The array with all the star IDs; should not be modified\n",
    "                        but returned for consistency\n",
    "    Notes\n",
    "    -----\n",
    "    1) Average magnitude is the converted magnitude of the average flux\n",
    "    2) The error for avgmag is the the quadratic error ex. (e1^2 + e2^2 + .. + eN^2)^(1/2) / N\n",
    "    3) The fluxes are just converted from the magnitudes\n",
    "    \"\"\"\n",
    "    # Create new columns\n",
    "    filler = np.arange(len(tab))\n",
    "    c1 = Column(data = filler, name = 'avgmag',        dtype = np.float64)\n",
    "    c2 = Column(data = filler, name = 'avgmagerr',     dtype = np.float64)\n",
    "    c3 = Column(data = filler, name = 'flux',          dtype = np.float64)\n",
    "    c4 = Column(data = filler, name = 'fluxerr',       dtype = np.float64)\n",
    "    c5 = Column(data = filler, name = 'avgflux',       dtype = np.float64)\n",
    "    c6 = Column(data = filler, name = 'avgfluxerr',    dtype = np.float64)\n",
    "    tab.add_column(c1)\n",
    "    tab.add_column(c2)\n",
    "    tab.add_column(c3)\n",
    "    tab.add_column(c4)\n",
    "    tab.add_column(c5)\n",
    "    tab.add_column(c6)\n",
    "    \n",
    "    starIDarr = np.unique(tab['id'])\n",
    "    for star in starIDarr:\n",
    "        starindexes = np.where(tab['id'] == star)[0]    # the indexes in the tab of where the star is\n",
    "        currmags = np.array(tab[starindexes]['mag'])    # the current magnitudes \n",
    "        currmagerr = tab[starindexes]['magerr']         # the current magnitude errors (type = class <'astropy.table.column.Column'>)\n",
    "        currfluxes = convertmag2flux(currmags)          # the current fluxes\n",
    "        #currfluxerr = np.array([2.303*flux*magerr for flux, magerr in zip(currfluxes, currmagerr)]) # Using antilog error propagation\n",
    "        currfluxerr = np.array([flux*magerr/1.086 for flux, magerr in zip(currfluxes, currmagerr)])\n",
    "        # http://www.astro.wisc.edu/~mab/education/astro500/lectures/a500_lecture2_s13.pdf Slide #11\n",
    "        \n",
    "        avgmag = convertflux2mag(np.mean(currfluxes))   # the absolute magnitude\n",
    "        avgerror = lambda errarr: np.sqrt(np.sum(errarr**2)) / len(errarr)\n",
    "        avgmagerr = avgerror(currmagerr)\n",
    "        avgfluxerr = avgerror(currfluxerr)\n",
    "        for i, index in enumerate(starindexes):         # input the abs mag and abs magerr\n",
    "            tab[index]['avgmag'] = avgmag\n",
    "            tab[index]['avgmagerr'] = avgmagerr  \n",
    "            tab[index]['flux'] = currfluxes[i]\n",
    "            tab[index]['fluxerr'] = currfluxerr[i]\n",
    "            tab[index]['avgflux'] = np.mean(currfluxes)\n",
    "            tab[index]['avgfluxerr'] = avgfluxerr\n",
    "    \n",
    "    return tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_filter(tab, min_num_obs, flux_ratio, low, high, remove_stars):\n",
    "    # this is assuming that tab only has flux values (NO magnitude)\n",
    "    starIDarr = np.unique(tab['id'])                  # collect all the star IDs\n",
    "    num_stars0 = np.double(len(starIDarr))\n",
    "    num_obs0 = np.double(len(tab))\n",
    "    print '******************************************'\n",
    "    print '************** START FILTER **************'\n",
    "    print '******************************************'\n",
    "    print 'Initial number of observations:\\t', len(tab) \n",
    "    \n",
    "    tab = make_avgmagandflux(tab)\n",
    "    tab = remove_certain_star(tab, remove_stars)      \n",
    "    tab = tab[np.where(tab['flux']/tab['fluxerr'] > flux_ratio)[0]]     # S/N ratio for flux is greater than flux_ratio\n",
    "    tab = remove_stars_tab(tab, min_num_obs)                            # Remove rows with less than min num of observations\n",
    "    tab = sigmaclip_starmagflux(tab, low, high)                         # Sigmaclip the fluxes for each star\n",
    "    tab = sigmaclip_delmagdelflux(tab, low, high)                       # Sigmaclip the delta fluxes as a whole\n",
    "   \n",
    "    print 'Number of observations after filtering:\\t', len(tab)\n",
    "    print 'Percent of observations kept:\\t', len(tab)/num_obs0 * 100\n",
    "    print 'Number of stars after filtering:\\t', len(starIDarr)\n",
    "    print 'Percent of stars kept:\\t', len(starIDarr)/num_stars0\n",
    "    print '******************************************'\n",
    "    print '*************** END FILTER ***************'\n",
    "    print '******************************************\\n'\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Chi-square \n",
    "This part sets up the functions that will be used for MCMC\n",
    "\n",
    "(1) lnprior [prior]\n",
    "This function ensures that a set of parameters are within the constraints\n",
    "\n",
    "(2) chisqstar [helper for the likelihood]\n",
    "This function computes the chi-square of one star\n",
    "\n",
    "(3) lnlike [likelihood]\n",
    "This function sums all of the chi-squares from each star and multiplies by -.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lnprior(params):\n",
    "    realparams = params\n",
    "    if USE_F:\n",
    "        realparams, lnf = params[:-1], params[-1]\n",
    "    if -.1 < realparams[0] < .1:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "    \n",
    "def chisqstar(starrows, params, func2fit):\n",
    "    ''' \n",
    "    Purpose\n",
    "    -------\n",
    "    Compute the chi-square of one star\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    starrows:   The rows of the table corresponding to a certain star (Astropy Table subset)\n",
    "    params:     The parameters corresponding to the function that is being fit\n",
    "    func2fit:   The function that is being fit\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    starsqsum:  The chi-square value for the star\n",
    "    '''\n",
    "    starvals = starrows['flux']\n",
    "    starvalerrs = starrows['fluxerr']\n",
    "    func = lambda p, x, y: np.sum(func2fit(x,y) * np.asarray(p)) + 1           # The 'delta' function\n",
    "    if SCALE2ONE:\n",
    "        fits = [func(params, (row['x']-CHIPXLEN/2)/(CHIPXLEN/2), (row['y']-CHIPYLEN/2)/(CHIPYLEN/2)) for row in starrows]\n",
    "    else:\n",
    "        fits = [func(params, row['x'], row['y']) for row in starrows]\n",
    "    avgf = np.mean(starvals/fits)                                              # Our 'expected' value for the Flux\n",
    "   \n",
    "    def get_sigmasq():\n",
    "        if USE_F:\n",
    "            return np.asarray((starvalerrs/fits))**2 + np.exp(2*lnf)*avgf**2\n",
    "        return np.asarray((starvalerrs/fits))**2\n",
    "            \n",
    "    starsq = (starvals/fits - avgf)**2 / get_sigmasq() + np.log(get_sigmasq()) # ignore the 2pi since that is just a constant for the chisq\n",
    "    starsq = np.asarray(starsq)\n",
    "    starsqsum = np.sum(starsq)\n",
    "    return starsqsum   \n",
    "       \n",
    "def lnlike(params, tab, func2fit, num_cpu=4):\n",
    "    realparams = params\n",
    "    if USE_F:\n",
    "        realparams, lnf = params[:-1], params[-1]\n",
    "    starIDarr = np.unique(tab['id'])\n",
    "    # np.where(tab['id'] == star)[0]                -- the indexes in tab where a star is located\n",
    "    # tab[np.where(tab['id'] == star)[0]]           -- \"starrows\" = the rows of tab for a certain star\n",
    "    # chisqstar(tab[np.where(tab['id'] == star)[0]])-- the chi squared for just one star\n",
    "    starsqsums = np.asarray([chisqstar(tab[np.where(tab['id'] == star)[0]], realparams, func2fit) for star in starIDarr])     # an array of the sq of sums for each star\n",
    "    totalsqsum = np.sum(starsqsums)\n",
    "    return -0.5 * totalsqsum\n",
    "\n",
    "def lnprob(params, tab, func2fit):\n",
    "    lp = lnprior(params)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(params, tab, func2fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function (get_pos) creates the initial tiny gaussian balls -- aka the initial locations of the walkers. \n",
    "It makes sure that these initial locations are within the constraints of the prior, and if not, then they are thrown out. \n",
    "If some walkers are thrown out, new ones are generated so that there are nwalkers by the end.\n",
    "A warning is thrown if it takes longer than 45 seconds to get the initial locations to let the user know that a different scale factor may be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pos(ndim, nwalkers, scale_factor, base_coeff):\n",
    "    ''' Creates the initial tiny gaussian balls '''\n",
    "    pos = [base_coeff + scale_factor*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "    def filter_pos(pos):\n",
    "        # filters the pos by making sure they are within the prior\n",
    "        remove_pos = np.array([])    \n",
    "        for i, elem in enumerate(pos):\n",
    "            lp = lnprior(elem)\n",
    "            if not np.isfinite(lp):\n",
    "                remove_pos = np.append(remove_pos, i)\n",
    "        pos = np.delete(pos, remove_pos, axis = 0)\n",
    "        return pos\n",
    "    start_time = time.time()\n",
    "    pos = filter_pos(pos)\n",
    "    \n",
    "    # the process below ensures that number of walkers equals the length of pos\n",
    "    while len(pos) - nwalkers != 0 and len(pos) - nwalkers < 0:\n",
    "        num = len(pos) - nwalkers\n",
    "        newpos = [base_coeff + scale_factor*np.random.randn(ndim) for i in range(-1*num)]\n",
    "        pos = np.append(pos, newpos, axis = 0)\n",
    "        pos = filter_pos(pos)\n",
    "        if len(pos) - nwalkers > 0:\n",
    "            difference = len(pos) - nwalkers\n",
    "            pos = pos[:-difference]\n",
    "        if time.time()-start_time > 45.0:\n",
    "            warnings.warn(\"Warning: Finding the intial MCMC walkers is taking too long\")\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing MCMC\n",
    "This part does MCMC optimizing.\n",
    "\n",
    "Steps in doing MCMC:\n",
    "* Get the function based on the chosenfunc and n\n",
    "* Reduce the table to make it take up less space (assuming that it only has flux-type information)\n",
    "* Create the initial conditions\n",
    "* Create the initial locations of the walkers\n",
    "* Create the MCMC sampler (emcee.EnsembleSampler)\n",
    "* Run a burnin of the sampler (if provided) to place the initial locations of the walkers in better locations -- typically it is 10-20% of nsteps\n",
    "* Run the samples for nsteps -- if you want to save the locations of each walker for each step, then provide a file location txtfil. ex txtfil = '/user/dkossakowski/cheb1_100w_700s_coeff.txt'\n",
    "* Get the samples from the sampler (sampler.chain) to perform analyses \n",
    "* Get the MCMC coefficients and their errors \n",
    "    - valswerrs is an array of tuples where each tuple corresponds to an MCMC coefficient and errors\n",
    "* Normalize the coefficients using integration\n",
    "* Save the MCMC coefficients to a file if mcmcfil is provided. \n",
    "ex mcmcfil = '/user/dkossakowski/cheb1_100w_700s_mcmc.txt'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Example\n",
    ">>> tab = ... # from do_table and filter_table\n",
    ">>> nsteps, nwalkers = 100, 100\n",
    ">>> chosenfunc, n = 'cheb', 1\n",
    ">>> scale_factor = 1e-1\n",
    ">>> burnin = 0\n",
    ">>> txtfil = ''\n",
    ">>> mcmcfil = ''\n",
    ">>> sampler, samples, valswerrs, mcmccoeff,  f, ndim = do_MCMC(tab, nsteps, nwalkers, chosenfunc, n, scale_factor, burnin, txtfil, mcmcfil)\n",
    ">>> print mcmccoeff\n",
    "\n",
    ">>> print valswerrs\n",
    "\n",
    ">>> print ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_MCMC(tab, nsteps, nwalkers, chosenfunc, n, scale_factor, burnin, txtfil, mcmcfil):\n",
    "\n",
    "    print '******************************************'\n",
    "    print '*************** START MCMC ***************'\n",
    "    print '******************************************'\n",
    "    \n",
    "    print 'Number of walkers:', nwalkers\n",
    "    print 'Number of steps:', nsteps\n",
    "    \n",
    "    ### Get the function\n",
    "    func2read, func2fit = get_function(chosenfunc, n)\n",
    "    print 'Function that is being fit:', chosenfunc + str(n)\n",
    "    print func2read\n",
    "    ###\n",
    "    \n",
    "    ### Reduce the Table so that it doesn't have unused Columns that take up memory/time\n",
    "    tabreduced = np.copy(tab)               \n",
    "    tabreduced = Table(tabreduced)\n",
    "    tabreduced.remove_columns(['avgflux','avgfluxerr'])\n",
    "    ###\n",
    "    \n",
    "    ### Set up the initial coefficients \n",
    "    if USE_F:\n",
    "        initialcoeff = np.zeros(len(func2read)+1)\n",
    "        initialcoeff[-1] = np.log(F)\n",
    "    else:\n",
    "        initialcoeff = np.zeros(len(func2read))\n",
    "    ###\n",
    "    \n",
    "    ### Determine the initial locations of the walkers\n",
    "    ndim = len(initialcoeff)\n",
    "    start_time = time.time()\n",
    "    pos = get_pos(ndim, nwalkers, scale_factor, base_coeff=initialcoeff)\n",
    "    print 'Time it took to get the initial positions of the walkers:', time.time() - start_time, 'seconds'\n",
    "    ### \n",
    "    \n",
    "    start_time = time.time()\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=(tabreduced, func2fit,))\n",
    "    \n",
    "    if burnin:\n",
    "        pos = sampler.run_mcmc(pos, burnin)[0]\n",
    "        sampler.reset()\n",
    "\n",
    "    if txtfil:\n",
    "        writefil = txtfil \n",
    "        f = open(writefil, \"w\")\n",
    "        f.write('#chosenfunc: ' + chosenfunc + str(n) + '\\n')\n",
    "        f.write('#nsteps: '   + str(nsteps)     + '\\n')\n",
    "        f.write('#nwalkers: ' + str(nwalkers)   + '\\n')\n",
    "        f.write('#ndim: '     + str(ndim)       + '\\n')\n",
    "        f.close()\n",
    "        \n",
    "    for i, result in enumerate(sampler.sample(pos, iterations=nsteps, storechain=True)):\n",
    "        if i%20 == 0: print 'step #', i \n",
    "        if txtfil:\n",
    "            position = result[0]\n",
    "            f = open(writefil, \"a\")\n",
    "            f.write('#nstep ' + str(i) + '\\n')\n",
    "            for k in range(position.shape[0]):\n",
    "                #f.write('{0:d} {1:s}\\n'.format(k, \"\".join(str(position[k]))))\n",
    "                for elem in position[k]:\n",
    "                    f.write(str(elem) + ' ')\n",
    "                #f.write(str(position[k]))\n",
    "                f.write('\\n')\n",
    "            f.close()\n",
    "    samples = sampler.chain[:, :, :].reshape((-1, ndim))\n",
    "    \n",
    "    print 'Time it took to do MCMC:'\n",
    "    print time.time() - start_time, 'seconds'\n",
    "    print (time.time() - start_time)/60., 'minutes'\n",
    "    print (time.time() - start_time)/3600., 'hours'\n",
    "    \n",
    "    ### Get the true values\n",
    "    if USE_F:\n",
    "        samples[:, -1] = np.exp(samples[:, -1])\n",
    "    valswerrs = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                                zip(*np.percentile(samples, [16, 50, 84], axis=0)))\n",
    "    valswerrs = np.asarray(valswerrs)\n",
    "    mcmccoeff = valswerrs.T[0]   \n",
    "    mcmccoeff[0] += 1 # Because we defined p0 as p0-1 so we are just adding the 1 back in\n",
    "    ###\n",
    "    \n",
    "    ###\n",
    "    if USE_F:\n",
    "        f = mcmccoeff[-1]\n",
    "        mcmccoeff = mcmccoeff[:-1]\n",
    "    else:\n",
    "        f = 0\n",
    "    ###\n",
    "    \n",
    "    ### Normalize\n",
    "    int_resmcmc = integrate.nquad(funcintegrate, [bounds_x(), bounds_y()], args = (mcmccoeff,chosenfunc,n,))[0]  \n",
    "    int_resmcmc /= area()\n",
    "    mcmccoeff /= int_resmcmc\n",
    "    print\n",
    "    print 'MCMC Coefficients:'\n",
    "    print mcmccoeff\n",
    "    ###\n",
    "    \n",
    "    if mcmcfil:\n",
    "        writefil = mcmcfil\n",
    "        f = open(writefil, \"w\")\n",
    "        f.close()\n",
    "        \n",
    "        # Make it easy to copy and paste\n",
    "        for coeff in mcmccoeff:\n",
    "            f = open(writefil, \"a\")\n",
    "            f.write(str(coeff)+', ')\n",
    "            f.close()\n",
    "        # Format it just down the line\n",
    "        f = open(writefil, \"a\")\n",
    "        f.write('\\n \\n')\n",
    "        f.close()\n",
    "        for coeff in mcmccoeff:\n",
    "            f = open(writefil, \"a\")\n",
    "            f.write(str(coeff)+'\\n')\n",
    "            f.close()\n",
    "        # Include the errors  \n",
    "        f = open(writefil, \"a\")\n",
    "        f.write('\\n \\n')\n",
    "        f.close()\n",
    "        for coeff in valswerrs:\n",
    "            f = open(writefil, \"a\")\n",
    "            f.write(str(coeff[0]) + ' +' + str(coeff[1]) + ' -' + str(coeff[2]) + '\\n')\n",
    "            f.close()\n",
    "        # The function written out\n",
    "        f = open(writefil, \"a\")\n",
    "        f.write('\\n \\n')\n",
    "        f.write(chosenfunc+str(n) + '\\n')\n",
    "        f.close()\n",
    "        \n",
    "        for char in func2read:\n",
    "            f = open(writefil, \"a\")\n",
    "            f.write(str(char)+'\\n')\n",
    "            f.close()\n",
    "    \n",
    "    print '******************************************'\n",
    "    print '**************** END MCMC ****************'\n",
    "    print '******************************************\\n'\n",
    "    return [sampler, samples, valswerrs, mcmccoeff,  f, ndim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Analysis - modifiying samples\n",
    "In case you forgot to put in a burnin value, you can use get_samplerchain to choose where to start and where to end in making the samples. This can be better because you can look at the walker paths after the MCMC and then decide where to start/end the analysis. This is useful for making better triangle plots, which gives a better gaussian shape along the diagonal, and hence gives more accurate values for the coefficients and errors.\n",
    "\n",
    "The get_truevalues function then takes the 'new' samples and computes the 'new' mcmc coefficients and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_samplerchain(sampler, start, end, ndim, nsteps):\n",
    "    if start < 0: start = 0\n",
    "    if end > nsteps: end = nsteps\n",
    "    samp = sampler.chain[:, start:end, :].reshape((-1, ndim))\n",
    "    return samp\n",
    "\n",
    "def get_truevalues(samples):\n",
    "    if USE_F:\n",
    "        samples[:, -1] = np.exp(samples[:, -1])\n",
    "    valswerrs = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                                zip(*np.percentile(samples, [16, 50, 84], axis=0)))\n",
    "    valswerrs = np.asarray(valswerrs)\n",
    "    mcmccoeff = valswerrs.T[0]   \n",
    "    mcmccoeff[0] += 1 # Because we defined p0 as p0-1 so we are just adding the 1 back in\n",
    "    \n",
    "    if USE_F:\n",
    "        f = mcmccoeff[-1]\n",
    "        mcmccoeff = mcmccoeff[:-1]\n",
    "    else:\n",
    "        f = 0\n",
    "        \n",
    "    int_resmcmc = integrate.nquad(funcintegrate, [bounds_x(), bounds_y()], args = (mcmccoeff,chosenfunc,n,))[0]  \n",
    "    int_resmcmc /= area()\n",
    "    mcmccoeff /= int_resmcmc\n",
    "    return [mcmccoeff, valswerrs, f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating FITS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fits(filfits, chosenfunc, n, coeff):\n",
    "    func2read, func2fit = get_function(chosenfunc, n)\n",
    "    fits.writeto(filfits, convert2mesh(func2fit, coeff, xpixel=np.arange(CHIPXLEN), ypixel=np.arange(CHIPYLEN))[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Walker Paths and Triangle Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotwalkerpaths(sampler, coeff_num, start, end, nsteps):\n",
    "    ''' \n",
    "    Purpose\n",
    "    -------\n",
    "    Return the plots of walker paths for your choice of num_subplots -- \n",
    "    Warning: if num_subplots is greater or equal to 5, then the figure gets too crowded.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sampler:        The MCMC sampler\n",
    "    coeff_num:      An array or list of coefficients whose walker paths will be plotted\n",
    "    start:          The beginning of the sampler chain\n",
    "    end:            The end of the sampler chain\n",
    "    nsteps:         The number of steps each walker takes\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    fig:            The figure with subplots of the walker paths for the given coeff_num\n",
    "    '''\n",
    "    if start < 0: start = 0\n",
    "    if end > nsteps: end = nsteps\n",
    "    num_subplots = len(coeff_num)\n",
    "    fig, axes = plt.subplots(num_subplots, 1, sharex=True)\n",
    "    for axnum, coeff_i in zip(range(num_subplots), coeff_num):\n",
    "        axes[axnum].plot(sampler.chain[:, start:end, coeff_i].T, color=\"k\", alpha=0.4)\n",
    "        axes[axnum].yaxis.set_major_locator(MaxNLocator(5))\n",
    "        axes[axnum].set_ylabel('Coeff #' + str(coeff_i))\n",
    "        axes[axnum].set_xticklabels(np.arange(start,end+1,10))\n",
    "    fig.tight_layout(h_pad=0.0)\n",
    "    return fig\n",
    "\n",
    "def plotwalkerpathsmult(sampler, savefigloc, chosenfunc, n):\n",
    "    ''' \n",
    "    Purpose\n",
    "    -------\n",
    "    Save the plots of the walker paths for ALL coefficients. \n",
    "    Each figure/plot will have 4 subplots.\n",
    "    This function SAVES the figures.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sampler:        The MCMC sampler\n",
    "    savefigloc:     The folder location of where the figures will be saved\n",
    "    chosenfunc:     The name of the function that is being fit\n",
    "    n:              The order of the 2d chosenfunc\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    This function does not return anything but SAVES the figures to savefigloc\n",
    "    '''\n",
    "    func2read, func2fit = get_function(chosenfunc, n)\n",
    "    num_plots = len(func2read)/4 + 1 if len(func2read)%4 != 0 else len(func2read)/4 \n",
    "    for index, i in enumerate(np.arange(num_plots)*4):\n",
    "        start = i\n",
    "        end = i+4 \n",
    "        if end > len(func2read): end = len(func2read)\n",
    "        fig, axes = plt.subplots(4, 1, sharex=True)\n",
    "        axes[3].set_xlabel('Number of Steps', fontsize=16)\n",
    "        for axnum, coeffnum in zip(range(end-start), np.arange(start, end)):\n",
    "            axes[axnum].plot(sampler.chain[:, :, coeffnum].T, color=\"k\", alpha=0.4)\n",
    "            axes[axnum].yaxis.set_major_locator(MaxNLocator(5))\n",
    "            axes[axnum].set_ylabel('Coeff #' + str(axnum), fontsize=16)\n",
    "        fig.tight_layout(h_pad=0.0)\n",
    "        fig.savefig(savefigloc + 'walkerpath' + str(index+1) + '.png', dpi = 500)\n",
    "        \n",
    "def plottriangle(samples, func2read):\n",
    "    ''' Returns the triangle plot given the samples '''\n",
    "    labels = [str(i) + \"th Coeff\" for i in range(len(func2read))]\n",
    "    labels[1] = \"1st Coeff\"\n",
    "    labels[2] = \"2nd Coeff\"\n",
    "    labels[3] = \"3rd Coeff\"\n",
    "    fig = corner.corner(samples, labels=labels)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Meshgrid and the Image of the LFlat"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Examples of calling these functions\n",
    ">>> meshgird = plotmesh(convert2mesh(func2fit, coeff=mcmccoeff, xpixel=XPIX, ypixel=YPIX), \\\n",
    "             title = 'MCMC: ' + str(args.chosenfunc) + ' n = ' + str(args.n))\n",
    ">>> meshgrid.savefig('/user/dkossakowski/Meshgrid.png', dpi=500)             \n",
    "\n",
    ">>> zzfitmcmc = convert2mesh(func2fit, coeff=mcmccoeff, \\ xpixel=np.double(range(int(CHIPXLEN))), ypixel=np.double(range(int(CHIPYLEN))))[2]      \n",
    ">>> imgmcmc = plotimg(zzfitmcmc, title = 'MCMC: ' + args.chosenfunc + ' n = ' + str(args.n), fitplot = True)\n",
    ">>> imgmcmc.savefig('/user/dkossakowski/Lflat.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert2mesh(func2fit, coeff, xpixel, ypixel):\n",
    "    ''' Creates a mesh using the function, the coefficients and the x and y pixel values '''\n",
    "    if SCALE2ONE:\n",
    "        xpixel = (xpixel - CHIPXLEN/2)/(CHIPXLEN/2)\n",
    "        ypixel = (ypixel - CHIPYLEN/2)/(CHIPYLEN/2)\n",
    "    xx, yy = np.meshgrid(xpixel, ypixel, sparse = True, copy = False) \n",
    "    fmesh = func2fit(xx, yy)\n",
    "    coeff = np.asarray(coeff)\n",
    "    fmesh[0] = np.ones(len(xpixel))\n",
    "    zzfit = np.sum(fmesh * coeff, axis = 0)\n",
    "    return [xx, yy, zzfit]\n",
    "\n",
    "def plotmesh(a, title = ''):\n",
    "    ''' Returns the figure of the mesh grid plot '''\n",
    "    X, Y, Z = a                   # a is the xx yy and zz (2d array)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_wireframe(X, Y, Z, rstride=1, cstride=1, color='red')\n",
    "    ax.set_title(title)\n",
    "    plt.legend()\n",
    "    return fig\n",
    "\n",
    "def plotimg(img, title = '', fitplot = False):\n",
    "    '''\n",
    "    Purpose\n",
    "    -------\n",
    "    Return an imshow figure of the image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img:        The image (2d array)\n",
    "    title:      The title of the figure: Default = ''\n",
    "    fitplot:    True if the image is an LFlat -- ensures that the midpoint of the\n",
    "                colorbar is 1\n",
    "                False if the image is not an LFlat\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    fig:        The figure with the imshow plot of the img\n",
    "    '''\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('X Pixel', fontsize = 18);  ax.set_ylabel('Y Pixel', fontsize = 18)\n",
    "    extent = (0, CHIPXLEN, 0, CHIPYLEN)    \n",
    "\n",
    "    if fitplot:\n",
    "        scale = np.max([np.max(img) - 1, 1 - np.min(img)])\n",
    "        vmin = 1 - scale\n",
    "        vmax = 1 + scale\n",
    "    else:\n",
    "        vmin = np.min(img)\n",
    "        vmax = np.max(img)\n",
    "    cax = ax.imshow(np.double(img), cmap = 'viridis', interpolation='nearest', \\\n",
    "                                    origin='lower', extent=extent, vmin=vmin, vmax=vmax)\n",
    "    if fitplot:\n",
    "        c = np.linspace(1 - scale, 1 + scale, num = 9)\n",
    "        cbar = fig.colorbar(cax, fraction=0.046, pad=0.04, ticks = c)\n",
    "        cbar.ax.set_yticklabels(c)  # vertically oriented colorbar\n",
    "    else:\n",
    "        fig.colorbar(cax, fraction=0.046, pad=0.04)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous\n",
    "Below are functions that may be useful but aren't included in the main() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Star Info from the Table Data to a file\n",
    "Creating a file that holds information on the Table data:\n",
    "\n",
    "Star ID, Fluxes, Average Flux, Standard Deviation of Flux, Flux Errors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If we want to save all this information to a file\n",
    ">>> writefil = '/user/dkossakowski/tableinfo.txt'\n",
    ">>> tabinfo(writefil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tabinfo(writefil):\n",
    "    stars = np.unique(tab['id'])\n",
    "    f = open(writefil, \"w\")\n",
    "    f.close()\n",
    "    for star in stars:\n",
    "        tabstar = tab[np.where(tab['id']==star)[0]]\n",
    "        \n",
    "        f = open(writefil, \"a\")\n",
    "        f.write('Star #' + str(star) + '\\n')\n",
    "        f.write('Fluxes: ' + str(np.asarray(tabstar['flux'])))\n",
    "        f.write('\\nAverage Flux: ' + str(np.mean(tabstar['flux'])))\n",
    "        f.write('\\nStd Flux: ' + str(np.std(tabstar['flux'])))\n",
    "        f.write('\\nFlux Errors: ' + str(np.asarray(tabstar['fluxerr'])))\n",
    "        f.write('\\n\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and Plotting the Chi-squared by varying all the variables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we want to see what chi-squared looks like when we vary all coefficents by a dx specific to each coefficient.\n",
    "# If we want to see the evolution for cheb1\n",
    ">>> tab = ... # table after do_table and filter_table\n",
    ">>> fig = plotminimizechi(tab, chosenfunc='cheb', n=1, initialcoeff=[0,0,0,0], mcmccoeff=[.1,1e-3,1e-3,1e-3], num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minimizechi(tab, chosenfunc, n, initialcoeff, finalcoeff, num):\n",
    "    func2read, func2fit = get_function(chosenfunc, n)\n",
    "    diffarr = (finalcoeff - initialcoeff)/np.double(num)\n",
    "    chisqarr = np.array([])\n",
    "    for incr in range(num*4+1):\n",
    "        currparams = initialcoeff + incr*diffarr\n",
    "        currchisq = lnlike(currparams, tab, func2fit) * -2.\n",
    "        chisqarr = np.append(chisqarr, currchisq)\n",
    "    return [range(len(chisqarr)), chisqarr]\n",
    "def plotminimizechi(tab, chosenfunc, n, initialcoeff, mcmccoeff, num=20):\n",
    "    x, y = minimizechi(tab, chosenfunc, n, initialcoeff, mcmccoeff, num)\n",
    "    fig = plt.figure(facecolor = 'white', figsize = (12,5))\n",
    "    plt.title('Evolution of $\\chi^2$', fontsize=18)\n",
    "    plt.axhline(y = 10516.8849567, ls = '--', label = 'Sum of scatters with current L-Flat: ' + str(10516.88))\n",
    "    plt.plot(x, y,'o')\n",
    "    plt.plot(x[np.argmin(y)], y[np.argmin(y)], 'ko', label = 'Sum of scatters with new L-Flat: ' + str(np.min(y)))\n",
    "    plt.ylabel('$\\chi^2$', fontsize=18)\n",
    "    labels = ['Initial Coeff.', 'MCMC Coeff.', 'Beyond Coeff.']\n",
    "    plt.xticks([0,num*2,num*4], labels, rotation=10)\n",
    "    plt.legend(loc=0)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and Plotting the Chi-squared by just varying one coefficient"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we want to see what chi-squared looks like when we vary only one coefficient but keep the rest constant. We vary it by a dx until it reaches mult*current_chisq. Let's say the current_chisq is 100 and mult is 15, so we vary that one variable by dx until the chi squared reaches 1500.\n",
    "# If we want to vary the 2nd coefficient with dx of .005 until it reaches 15*current_chisq\n",
    ">>> tab = ... # table after do_table and filter_table\n",
    ">>> chosenfunc, n = 'cheb', 1\n",
    ">>> mcmccoeff = [1, 1e-3, 1e-3, 1e-3]\n",
    ">>> varycoeff2plot = plotchisq_varyone(tab, chosenfunc, n, mcmccoeff, coeff_num=2, dx=.005, mult=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chisq_varyone(tab, chosenfunc, n, mcmccoeff, coeff_num, dx, mult):\n",
    "    func2read, func2fit = get_function(chosenfunc, n)\n",
    "    chisqorig = lnlike(mcmccoeff, tab, func2fit) * -2\n",
    "    mcmccoefforig = np.copy(mcmccoeff)\n",
    "    currchisq = chisqorig\n",
    "    chisqleft = []\n",
    "    k=0\n",
    "    while currchisq <= mult * chisqorig:\n",
    "        mcmccoeff[coeff_num] -= dx*k\n",
    "        currchisq = lnlike(mcmccoeff, tab, func2fit) *-2\n",
    "        chisqleft = chisqleft + [currchisq]\n",
    "        k+=1\n",
    "    xleft = range(len(chisqleft))\n",
    "    \n",
    "    currchisq = chisqorig\n",
    "    chisqright = []\n",
    "    mcmccoeff = np.copy(mcmccoefforig)\n",
    "    k=1\n",
    "    while currchisq <= mult * chisqorig and currchisq > 0:\n",
    "        mcmccoeff[coeff_num] += dx*k\n",
    "        currchisq = lnlike(mcmccoeff, tab, func2fit)*-2\n",
    "        chisqright = chisqright + [currchisq]\n",
    "        k+=1\n",
    "    xright = range(len(chisqright)) + np.ones(len(chisqright))\n",
    "    xright = xright.tolist()\n",
    "        \n",
    "    chisqleft.reverse()\n",
    "    chisqarr = chisqleft + chisqright\n",
    "    \n",
    "    xleft = xleft * np.ones(len(xleft)) * -1\n",
    "    xleft = xleft.tolist()\n",
    "    xleft.reverse()\n",
    "    x = xleft + xright\n",
    "    \n",
    "    mcmccoeff = np.copy(mcmccoefforig)\n",
    "    return [x, chisqarr]\n",
    "\n",
    "def plotchisq_varyone(tab, chosenfunc, n, mcmccoeff, coeff_num, dx, mult):\n",
    "    fig = plt.figure()\n",
    "    x, y = chisq_varyone(tab, chosenfunc, n, mcmccoeff, coeff_num, dx, mult)\n",
    "    plt.plot(x, y, 'o')\n",
    "    plt.title('Varying coeff: ' + str(coeff_num) + ' dx: ' + str(dx) + ' mult: ' + str(mult) +\\\n",
    "                '\\nMinimum value: ' +str(np.min(y)) + ' at index ' + str(x[np.argmin(y)]) +\\\n",
    "                 ' ' + chosenfunc + str(n))\n",
    "    plt.ylabel('$\\chi^2$', fontsize=18)\n",
    "    plt.xlabel('Number of dx', fontsize=18)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning (for imshowing the number of observations and averages in a bin)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">>> tab = ... # table after do_table and filter_table\n",
    ">>> XBIN = YBIN = 20.0\n",
    ">>> zzorig, zznum, zzavg = do_bin(tab, XBIN, YBIN)\n",
    ">>> print zzorig[5]\n",
    "[array([ 0.00023284])\n",
    " array([ 0.01983039, -0.00145973,  0.01056809, -0.01061441, -0.01983066])\n",
    " array([ 0.00267247,  0.00685187])\n",
    " array([ 0.00174744, -0.01017541, -0.03359517,  0.00592496])\n",
    " array([ 0.02756333,  0.00544482,  0.00915585, -0.00101471,  0.02697316,\n",
    "        0.02981471])\n",
    " array([-0.01430303,  0.00449643,  0.01285761,  0.01849345,  0.00637327,\n",
    "        0.01943395])\n",
    " array([ 0.01489536,  0.01670588,  0.01931731,  0.00718535, -0.01051641,\n",
    "        0.0069516 ,  0.02095969,  0.01661904,  0.01101649])\n",
    " array([ 0.02872046,  0.00449643,  0.00727579,  0.00634848])\n",
    " array([ 0.01962208, -0.00663375,  0.03994075])\n",
    " array([-0.01621539,  0.00285751, -0.00370044])\n",
    " array([ 0.04173726,  0.01708722, -0.00147671,  0.04629443])\n",
    " array([ 0.02084122,  0.0177456 ,  0.03095387, -0.0154467 ,  0.01868341,\n",
    "        0.01762992])\n",
    " None array([ 0.00220877, -0.00697954,  0.03178656, -0.00385369])\n",
    " array([ 0.0291973 , -0.01116659,  0.01093477,  0.0035133 , -0.04502954,\n",
    "       -0.05210935, -0.00926138])\n",
    " array([-0.01702285,  0.00206499]) None array([-0.0031986 ,  0.00417323])\n",
    " array([ 0.00699686]) array([-0.03861235])]\n",
    ">>> print zznum[5]\n",
    " [1 5 2 4 6 6 9 4 3 3 4 6 0 4 7 2 0 2 1 1]\n",
    ">>> print zzavg[5]\n",
    " [0.00023284459087312257 -0.00030126397879517086 0.0047621733880146167\n",
    " -0.0090245456911710563 0.016322857972755633 0.0078919456029549837\n",
    " 0.011459367319056965 0.011710290565471876 0.017643025275300803\n",
    " -0.0056861038054298978 0.025910549149100549 0.015067884977372601 0\n",
    " 0.0057905256458290356 -0.010560213051478475 -0.0074789323493013541 0\n",
    " 0.00048731235688013281 0.0069968566058638071 -0.038612353507757553]\n",
    "# Plot an imshow image of the number of observations in a bin\n",
    ">>> plt.show(plotimg(zznum, title = 'Number of Observations in a Bin'))\n",
    "# Plot an imshow image of the normalized delta fluxes binned\n",
    ">>> plt.show(plotimg(zzavg, title = 'Normalized Delta Fluxes Binned'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_bin(tab, xbin, ybin):  \n",
    "    \"\"\"\n",
    "    Purpose\n",
    "    -------\n",
    "                    To bin all the observations\n",
    "    Parameters\n",
    "    ----------\n",
    "    tab:            The Astropy Table with all the information\n",
    "    xbin:           number of bins in the x direction\n",
    "    ybin:           number of bins in the y direction\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    [zzorig, zznum, zzavg]\n",
    "    zzorig:         2D array of size xbin * ybin -- the original one -- where if \n",
    "                    there is nothing in a bin, 'None' is the element; \n",
    "                    and if there are multiple points/fluxes in the bin, \n",
    "                    there is an array of the normalized delta fluxes\n",
    "    zznum:          2D array of size xbin * ybin -- the number one -- where its\n",
    "                    value in a bin is the number of observations in that bin\n",
    "                    (helpful to imshow if want to see where the observations lie)\n",
    "    zzfinal:        2D array of size xbin * ybin -- the final one -- where the \n",
    "                    averages of each bin are taken, and if there was nothing in \n",
    "                    a bin, the average is set to 0             \n",
    "    \n",
    "    Notes/Problems/To Do\n",
    "    --------------------\n",
    "    **  For creating zz as a 2D array of size xbin * ybin with all the values \n",
    "        being set to 'None' causes some 'FutureWarnings' and I don't really know \n",
    "        how to solve the issue and go around it\n",
    "     \n",
    "    \"\"\"\n",
    "    xall = np.asarray(tab['x'])\n",
    "    yall = np.asarray(tab['y'])\n",
    "    delfluxall = np.asarray((tab[SPACE_VAL] - tab['avg'+SPACE_VAL]) / tab['avg'+SPACE_VAL]) # normalized\n",
    "    \n",
    "    # Initialize an empty 2D array for the binning;\n",
    "    # Create xbinarr and ybinarr as the (lengths of xbin and ybin, respectively);\n",
    "    #     to make up the bins\n",
    "    # Find dx and dy to help later with binning x+dx and y+dy\n",
    "    zz = np.array([np.array([None for i in range(np.int(xbin))]) for j in range(np.int(ybin))])\n",
    "    xbin, ybin = np.double(xbin), np.double(ybin)\n",
    "    xbinarr = np.linspace(0,     CHIPXLEN,     xbin,     endpoint = False)\n",
    "    ybinarr = np.linspace(0,     CHIPYLEN,     ybin,     endpoint = False)\n",
    "    dx, dy = xbinarr[1] - xbinarr[0], ybinarr[1] - ybinarr[0]\n",
    "    # Each element of xbinarr and ybinarr is the x and y value for a bin. \n",
    "    #    We are looking for the index/indicies that follow the \n",
    "    #    condition that the xall and yall are in a bin of x+dx and y+dy. \n",
    "    # The index/indicies that fall in this condition are stored in an array\n",
    "    #    called inbin \n",
    "    for i, x in enumerate(xbinarr):\n",
    "        for j, y in enumerate(ybinarr):\n",
    "            inbin = np.where((xall >= x) & (xall < x + dx) & \\\n",
    "                             (yall >= y) & (yall < y + dy))[0]    # indexes of points in a bin\n",
    "            if len(inbin):\n",
    "                zz[i][j] = delfluxall[inbin]\n",
    "            \n",
    "            \n",
    "    # Now deal with zz and take the averages in each bin \n",
    "    # Need to also build the x arrays, y arrays, and the delta magnitude arrays\n",
    "    #     which will be used for the 2D fit \n",
    "    zz = zz.T         \n",
    "    zzorig  = np.copy(zz)\n",
    "    zznum   = np.copy(zz)\n",
    "    zzavg   = np.copy(zz)\n",
    "    for i in range(len(xbinarr)):\n",
    "        for j in range(len(ybinarr)):\n",
    "            if zzavg[i][j] == None: # gives a futurewarning : comparison to `None` will result in an elementwise object comparison in the future.\n",
    "                zzavg[i][j] = 0\n",
    "                zznum[i][j] = 0\n",
    "            else:\n",
    "                delfluxavg = np.mean(zz[i][j])\n",
    "                zzavg[i][j] = delfluxavg\n",
    "                zznum[i][j] = len(zz[i][j])\n",
    "    return [zzorig, zznum, zzavg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotating 3D Scatter Plot GIF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we want to make a GIF for the rotating 3D scatter plot of normalized delta fluxes\n",
    ">>> tab = ... # table after do_table and filter_table\n",
    ">>> path3d = '/user/dkossakowski/FinalPresentation/Scatter3DRotate/'\n",
    ">>> x, y, z = tab['x'], tab['y'], (tab['flux'] - tab['avgflux'])/ tab['avgflux']\n",
    ">>> rotate3d(x, y, z, path3d, title = 'Normalized Delta Flux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate3d(x, y, z, folderpath, title = ''):\n",
    "    '''\n",
    "    Purpose\n",
    "    -------\n",
    "    To save figures of a rotating scatter plot to make a GIF of a rotating scatter plot\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y, z:       The 3D values for the scatter plot\n",
    "    folderpath:    The folder name of where all the files will be saved\n",
    "    title:         The title of the plots\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    This function does not return anything but SAVES the figures to folderpath\n",
    "    '''\n",
    "    for angle in range(0,360):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(x, y, z)\n",
    "        ax.view_init(30, angle)\n",
    "        ax.set_xlabel('X', fontsize = 18); ax.set_ylabel('Y', fontsize = 18)\n",
    "        ax.set_title(title, fontsize = 18)\n",
    "        fig.savefig(folderpath + str(angle)+'.png', dpi = 500)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stars and their Observations GIF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we want to make a GIF of the detector and the stars and their observations\n",
    "Or if we want to see where the stars lie on the detector\n",
    "\n",
    "# To see where all the stars and observations lie on the detector\n",
    "# Note: each color represents a star and its observations\n",
    ">>> plt.show(plotnumobsGIF(tab, num = 33, cmap = 'jet'))\n",
    "\n",
    "# To incrementally save the figures to make the GIF\n",
    ">>> length = len(np.unique(tab['id']))\n",
    ">>> for i in range(length) + np.ones(length):\n",
    ">>>    i = int(i)\n",
    ">>>    plotnumobsGIF(tab, num=i).savefig('/user/dkossakowski/FinalPresentation/NumObsGIF' + str(i) + '.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotnumobsGIF(tab, num, cmap = 'jet'):\n",
    "    '''\n",
    "    Purpose\n",
    "    -------\n",
    "    To plot where the stars and their obervations lie on the detector\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tab:        The Astropy Table\n",
    "    num:        The number of stars that we want to plot\n",
    "    cmap:       The color map which the stars will follow\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    fig:        The figure with the stars and observations\n",
    "    '''\n",
    "    fig = plt.figure()\n",
    "    plt.xlim([0,CHIPXLEN])\n",
    "    plt.ylim([0,CHIPYLEN])\n",
    "    plt.grid(True)\n",
    "    plt.title('Observation Locations', fontsize = 18)\n",
    "    plt.xticks(np.linspace(0, CHIPXLEN, 9))\n",
    "    plt.yticks(np.linspace(0, CHIPYLEN, 9))\n",
    "    plt.xlabel('X Pixel', fontsize = 18)\n",
    "    plt.ylabel('Y Pixel', fontsize = 18)\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "    stars = np.unique(tab['id'])\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, len(stars))]\n",
    "    for col, star in zip(colors[:num], stars[:num]):\n",
    "        tabstar = tab[np.where(tab['id'] == star)[0]]\n",
    "        plt.scatter(tabstar['x'], tabstar['y'], s=100, c=col, marker='*', lw=0.2)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walker Paths GIF"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we want to make a GIF of the walker paths\n",
    "Put this function into the do_MCMC function like so:\n",
    ">>> i, result in enumerate(sampler.sample(pos, iterations=nsteps, storechain=True)):\n",
    ">>>     def plotwalkerpathsGIF(coeff_num, start, end, nsteps):\n",
    ">>>         ...\n",
    ">>>         return fig\n",
    ">>>     walkerpathplot = plotwalkerpathsGIF([1,2], start=0, end=i)\n",
    ">>>     walkerpathplot.savefig(\"/user/dkossakowski/FinalPresentation/walkerpathGIF/\"+str(i)+\".png\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotwalkerpathsGIF(coeff_num, start, end, nsteps):\n",
    "    num_subplots = len(coeff_num)\n",
    "    fig, axes = plt.subplots(num_subplots, 1, sharex=False, figsize=(12, 5))\n",
    "    for axnum, coeff_i in zip(range(num_subplots), coeff_num):\n",
    "        axes[axnum].plot(sampler.chain[:, :, coeff_i].T[:end], color=\"k\", alpha=0.4)\n",
    "        axes[axnum].yaxis.set_major_locator(MaxNLocator(5))\n",
    "        axes[axnum].set_ylabel('Coeff #' + str(coeff_i))\n",
    "        axes[axnum].set_xticks(np.arange(0,nsteps,10))\n",
    "        axes[axnum].set_xlim([0,nsteps-1])                \n",
    "    fig.tight_layout(h_pad=0.0)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main() - Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--chiplen CHIPLEN] [--bin BIN] [--usef USEF] [-filt]\n",
      "                   [-mcmc] [-s2one] [--datafile DATAFILE] [--names NAMES]\n",
      "                   [--types TYPES] [--remnames REMNAMES]\n",
      "                   [--min_num_obs {0,1,2,3,4,5,6,7,8,9}]\n",
      "                   [--flux_ratio FLUX_RATIO] [--low LOW] [--high HIGH]\n",
      "                   [--remove_stars REMOVE_STARS] [--n {0,1,2,3,4,5,6,7}]\n",
      "                   [--chosenfunc {poly,cheb,leg}] [--nwalkers NWALKERS]\n",
      "                   [--nsteps NSTEPS] [--scale_factor SCALE_FACTOR]\n",
      "                   [--burnin BURNIN] [--filmcmc FILMCMC] [--filcoeff FILCOEFF]\n",
      "                   [--figpath FIGPATH] [--filfits FILFITS]\n",
      "__main__.py: error: unrecognized arguments: /Users/dkossakowski/Library/Jupyter/runtime/kernel-6ffc2524-16ec-416b-adac-045d25516764.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description=\"Perform MCMC to find the coefficients for the LFlat\")\n",
    "    \n",
    "    # Constants\n",
    "    parser.add_argument(\"--chiplen\", default=1024,\n",
    "                        help=\"The length of the chip: Default = 1024\")\n",
    "    parser.add_argument(\"--bin\", default=20,\n",
    "                        help=\"The bin number; used for plotting the meshgrid: Default = 20\")\n",
    "    parser.add_argument(\"--usef\", default=0.0, \n",
    "                        help=\"Input F if want to use the fudge factor: Default = 0.0: Should be between 0 and 1\")\n",
    "    \n",
    "    # True False arguments\n",
    "    parser.add_argument(\"-filt\", \"--filtertable\", action = \"store_false\", default=True,\n",
    "                        help=\"True if filtering the table: Default = True\")\n",
    "    parser.add_argument(\"-mcmc\", \"--mcmc\", action = \"store_false\", default=True,\n",
    "                        help=\"True if performing MCMC: Default = True\")\n",
    "    parser.add_argument(\"-s2one\", \"--scale2one\", action = \"store_false\", default=True,\n",
    "                        help=\"True if scaling from -1 to 1 (Preferred): Default = True\")\n",
    "    \n",
    "    # Table arguments\n",
    "    parser.add_argument(\"--datafile\", \n",
    "                        help=\"The location of the datafile\")  # PROBABLY SHOULD NOT BE OPTIONAL\n",
    "    parser.add_argument(\"--names\", default=['id', 'filenum', 'chip', 'x', 'y', 'mag', 'magerr'],\n",
    "                        help=\"The names for the table -- Need to have 'id' 'x' 'y' 'flux' 'fluxerr'\")\n",
    "    parser.add_argument(\"--types\", default=[int, int, int, np.float64, np.float64, np.float64, np.float64],\n",
    "                        help=\"The types for the table\")\n",
    "    parser.add_argument(\"--remnames\", default=['filenum', 'chip'],\n",
    "                        help=\"The names to remove from the table\")\n",
    "                        \n",
    "    # Filter Table aruments\n",
    "    parser.add_argument(\"--min_num_obs\", type=int, default=4, choices=range(10),\n",
    "                        help=\"The minimum number of observations required for each star: Default = 4\")\n",
    "    parser.add_argument(\"--flux_ratio\", type=int, default=5, \n",
    "                        help=\"The minimum flux signal to noise for an observation: Default = 5\")\n",
    "    parser.add_argument(\"--low\", type=np.double, default=3.0,\n",
    "                        help=\"The lower limit for the sigma clipping when filtering the table\")\n",
    "    parser.add_argument(\"--high\", type=np.double, default=3.0,\n",
    "                        help=\"The upper limit for the sigma clipping when filtering the table\")\n",
    "    parser.add_argument(\"--remove_stars\", default = [],\n",
    "                        help=\"A List of certain stars that should be removed from the data\")                    \n",
    "    # MCMC arguments\n",
    "    parser.add_argument(\"--n\", type=int, choices=range(8), default=1,\n",
    "                        help=\"The nth order of the fit: Default = 1\")\n",
    "    parser.add_argument(\"--chosenfunc\", type=str, choices=[\"poly\", \"cheb\", \"leg\"], default=\"cheb\",\n",
    "                        help=\"The functional form: Default = 'cheb'\")\n",
    "    parser.add_argument(\"--nwalkers\", type=int, default=10,\n",
    "                        help=\"The number of walkers: Default = 10\")\n",
    "    parser.add_argument(\"--nsteps\", type=int, default=10,\n",
    "                        help=\"The number of steps each walker takes: Default = 10\")\n",
    "    parser.add_argument(\"--scale_factor\", type=np.double, default=1e-1,\n",
    "                        help=\"The shape of the initial tiny gaussian balls: Default = 1e-1\")\n",
    "    parser.add_argument(\"--burnin\", type=int, default=0,\n",
    "                        help=\"The number of steps MCMC should do and then start from there: Default = 0\")    \n",
    "    \n",
    "    # Saving Data arguments\n",
    "    parser.add_argument(\"--filmcmc\", default ='',\n",
    "                        help=\"Name of file to save the MCMC coefficients\")\n",
    "    parser.add_argument(\"--filcoeff\", default = '',\n",
    "                        help=\"Name of file to save the locations of each walker from each step\")\n",
    "    parser.add_argument(\"--figpath\", default = '',\n",
    "                        help=\"The path of where the figures will be saved\")   \n",
    "    parser.add_argument(\"--filfits\", default = \"\",\n",
    "                       help=\"Name of file to save FITS file using MCMC coefficients\")\n",
    "    args = parser.parse_args()\n",
    "        \n",
    "    CHIPXLEN = CHIPYLEN = args.chiplen\n",
    "    XBIN = YBIN = args.bin\n",
    "    XPIX = np.linspace(0, CHIPXLEN, XBIN)\n",
    "    YPIX = np.linspace(0, CHIPYLEN, YBIN)\n",
    "    SCALE2ONE = args.scale2one\n",
    "    \n",
    "    if args.usef:\n",
    "        F = args.usef\n",
    "        USE_F = True\n",
    "    else:\n",
    "        USE_F = False\n",
    "    \n",
    "    table = do_table(fil=args.datafile, names=args.names, types=args.types, removenames=args.remnames)\n",
    "\n",
    "    if args.filtertable:\n",
    "        table = do_filter(table,                        \\\n",
    "                        min_num_obs=args.min_num_obs,   \\\n",
    "                        flux_ratio=args.flux_ratio,     \\\n",
    "                        low=args.low, high=args.high,   \\\n",
    "                        remove_stars=args.remove_stars)\n",
    "    \n",
    "    if args.mcmc:\n",
    "        sampler, samples, vaslwerrs, mcmccoeff, f, ndim = do_MCMC(table, \n",
    "                        nsteps=args.nsteps, nwalkers=args.nwalkers,         \\\n",
    "                        chosenfunc=args.chosenfunc, n=args.n,               \\\n",
    "                        scale_factor=args.scale_factor, burnin=args.burnin, \\\n",
    "                        txtfil=args.filcoeff, mcmcfil=args.filmcmc)\n",
    "        if args.figpath:\n",
    "            func2read, func2fit = get_function(args.chosenfunc, args.n)\n",
    "            \n",
    "            plotmesh(convert2mesh(func2fit, coeff=mcmccoeff, \\\n",
    "                                    xpixel=XPIX, ypixel=YPIX), \\\n",
    "                    title = 'MCMC: ' + str(args.chosenfunc) + ' n = ' + str(args.n)).savefig(args.figpath+'meshgrid.png',dpi=500)\n",
    "            plotwalkerpathsmult(sampler, args.figpath, args.chosenfunc, args.n)\n",
    "            \n",
    "            zzfitmcmc = convert2mesh(func2fit, coeff=mcmccoeff, xpixel=np.double(range(int(CHIPXLEN))), ypixel=np.double(range(int(CHIPYLEN))))[2]      # convert2mesh returns [xx, yy, zzfit]\n",
    "            imgmcmc = plotimg(zzfitmcmc, title = 'MCMC: ' + args.chosenfunc + ' n = ' + str(args.n), fitplot = True)\n",
    "            imgmcmc.savefig(args.figpath+'Lflat.png', dpi=500)\n",
    "            plottriangle(samples, func2read).savefig(args.figpath+'triangle.png', dpi=700)\n",
    "\n",
    "            print 'New files:'\n",
    "            print args.figpath + 'walker*.png' + ' : The paths of the walkers'\n",
    "            print args.figpath + 'triangle.png' + ' : The triangle plot'\n",
    "            print args.figpath + 'meshgrid.png' + ' : The meshgrid of the Lflat'\n",
    "            print args.figpath + 'Lflat.png' + ' : The Lflat (imshow)'\n",
    "            \n",
    "        if args.filfits:\n",
    "            create_fits(args.filfits, args,chosenfunc, args,n, mcmccoeff)\n",
    "            print 'FITS file: ' + args.filfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
